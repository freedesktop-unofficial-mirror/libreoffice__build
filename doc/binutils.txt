Improving binutils' symbol & reloc sorting efficiency:

// Improved binutils symbol sorting for cache efficiency ...
    + Unfortunately -Wl,-combreloc exports & re-imports
      the relocs before sorting them [ most odd ]

    + We sort .dynsym nicely (by elf hash)
	+ we fail to sort .dynstr
	    - in sequence of suffix order [!?]
	+ elf-strtab.c (_bfd_elf_strtab_finalize)
	    + does a sort - but only on a copy ...
		+ also assigns hard addresses [!]
	    + ultimately in bfd_strtab_add order ...
		+ can we sort earlier & influence that ?
	    + red herring:
	    	    + '_bfd_elf_export_symbol' ...
	    + _bfd_elf_merge_symbol (?)
	    + *Unfortunately*
		+ the sym table is already built & swapped out (?)

    + we want relocs sorted by absolute elf hash value
	+ Unfortunately - we don't have the symbol foo here
	+ which *really* sucks ...
	+ The relocs are typically just copied from the source
	  though so ... _bfd_elf_link_output_relocs ...
	    + the SymStrTab + contains all the symbols
	    + in the right order - given an index each
	    + unfortunately inaccessible by 'index' ...
    + Back the strhash with the actual string data ? [!?]
	+ thus avoiding foos ?

    + and we want symbols sorted by % hash_table_size
        + HACK: _bfd_elf_link_renumber_dynsyms [!?]
	    + sort as we renumber ?
	+ bfd_elf_final_link
	    + elf_link_hash_traverse ... elf_link_output_extsym
	    + [ elf_sort_symbol ? ]

    ** Could we have a flat array of entries ?
	+ we need Index [ it's a byte index ... ]
	+ urgh ...
		+ st_name is a byte offset into foo


    ** Problems:
	+ dynsym index order is: (bfd_elf_final_link):
	    + dummy_symbol [elf_link_output_sym ...]
	    + elf_link_hash_traverse (elf_link_output_extsym...)
		localsyms = true
	    + abfd->sections order
	    + local dynsyms ...
	    + elf_link_hash_traverse (elf_link_output_extsym)
		localsyms = false
    ** To Do:
	+ 'simply' - pre-quicksort on 
	    (elf_link_hash_entry):
	    ** h->u.elf_hash_value % hash_size [!?]
	+ iterate over that instead of the hash ...
	+ also sorts the strings by elf hash incidentally :-)

	+ bucketcount = elf_hash_table (finfo->info)->bucketcount;
	+ bucket = h->u.elf_hash_value % bucketcount;

	    + compute_bucket_count ...
		+ builds 'hashcodes' list ...
		+ used only locally ...

    ** What about _bfd_elf_link_renumber_dynsyms ...
	+ what about hash table removals
	    - surely they change the order of traversal ?

** Hack elf_link_hash_traverse
	+ in 2 modes: pre-sort & post sort.

** We want to sort before _bfd_elf_link_renumber_dynsyms:
	from bfd_elf_size_dynamic_sections ...
	    + bucketcount calculated on line 5787
		+ bfd_elf_size_dynamic_sections [4987->5816]
	    + renumber_dynsyms is line 5715
		+ [urk]

dltest.c - simple dlopen 100 times of libvcl:
Iter 0.12241 us
Iter 0.12255 us
Iter 0.12828 us

sorted alphabetically:
Iter 0.12222 us
Iter 0.12506 us
Iter 0.12137 us

just libvcl sorted by elf_hash % bucketcount:
Iter 0.11994 us
Iter 0.11950 us
Iter 0.11959 us

more libvcl ldd output re-linked:
     sal, libutl, libsot

unchanged:
Iter 0.36873 us
Iter 0.36727 us
Iter 0.3777 us
Iter 0.39592 us
Iter 0.41514 us -- outlier
Iter 0.38233 us

Avg: 0.3784 ( + 0.3845 with outlier)

changed:
Iter 0.35362 us
Iter 0.35221 us
Iter 0.3547 us
Iter 0.37611 us
Iter 0.38871 us
Iter 0.37706 us

Avg: 0.3671

** sorting relocs by elf hash
   + store the hash value as we write it out ?!
   + store an array of 'h' pointers per reloc ?
...
    + then we have an array of foo ...
	+ or ? ... symbol foo...
    + OR - store the symbol strings in a chunk
      instead & index by offsets ?
	+ can realloc take that ?
	+ can we work out the size in advance ?
	+ can we get a very-slow prototype ?
    + foo:
	+ just read-in the elf string tab anyway.
	+ it got emitted by bfd_stringtab_emit just above anyway.

    + relocations - point into dynsym ? - if so - horay ;-)
	+ we can use the previous sort / foo table too ?
	+ otherwise we screwed that up nastily [?]
	    + hmm.

    + relocs must have a dynsym ptr - since that's
      what we accelerate -Bdirect with ...

** TODO
	+ strip out the -Bdirect cruft ...
	+ dynsym sort:
		+ free array
	+ free 'sorted' (x 2)
		+ strip out the -Bdirect stuff ...
	+ check array_sorted etc. correctly initialized...
	+ copy types for 'int' foo form dynidx etc. [ long ]
	+ better string sort ?
		+ into same order ? - re-use '*h' ?


Measurements of string table sorting
Measurements of dynsym sorting [too]:

Before:
$ valgrind --tool=cachegrind /opt/OpenOffice/dltest ./librels-unsorted.so 
==27907== Cachegrind, an I1/D1/L2 cache profiler.
==27907== Copyright (C) 2002-2005, and GNU GPL'd, by Nicholas Nethercote et al.
==27907== Using LibVEX rev 1471, a library for dynamic binary translation.
==27907== Copyright (C) 2004-2005, and GNU GPL'd, by OpenWorks LLP.
==27907== Using valgrind-3.1.0, a dynamic binary instrumentation framework.
==27907== Copyright (C) 2000-2005, and GNU GPL'd, by Julian Seward et al.
==27907== For more details, rerun with: -v
==27907== 
--27907-- warning: Pentium 4 with 12 KB micro-op instruction trace cache
--27907--          Simulating a 16 KB I-cache with 32 B lines
Iter 2.1932 us
==27907== 
==27907== I   refs:      258,090,625
==27907== I1  misses:          9,976
==27907== L2i misses:          5,623
==27907== I1  miss rate:        0.00%
==27907== L2i miss rate:        0.00%
==27907== 
==27907== D   refs:       98,069,403  (73,455,788 rd + 24,613,615 wr)
==27907== D1  misses:      3,963,722  ( 3,943,112 rd +     20,610 wr)
==27907== L2d misses:        179,710  (   178,441 rd +      1,269 wr)
==27907== D1  miss rate:         4.0% (       5.3%   +        0.0%  )
==27907== L2d miss rate:         0.1% (       0.2%   +        0.0%  )
==27907== 
==27907== L2 refs:         3,973,698  ( 3,953,088 rd +     20,610 wr)
==27907== L2 misses:         185,333  (   184,064 rd +      1,269 wr)
==27907== L2 miss rate:          0.0% (       0.0%   +        0.0%  )


After:
$ valgrind --tool=cachegrind /opt/OpenOffice/dltest ./librels-sorted.so 
==27871== Cachegrind, an I1/D1/L2 cache profiler.
==27871== Copyright (C) 2002-2005, and GNU GPL'd, by Nicholas Nethercote et al.
==27871== Using LibVEX rev 1471, a library for dynamic binary translation.
==27871== Copyright (C) 2004-2005, and GNU GPL'd, by OpenWorks LLP.
==27871== Using valgrind-3.1.0, a dynamic binary instrumentation framework.
==27871== Copyright (C) 2000-2005, and GNU GPL'd, by Julian Seward et al.
==27871== For more details, rerun with: -v
==27871== 
--27871-- warning: Pentium 4 with 12 KB micro-op instruction trace cache
--27871--          Simulating a 16 KB I-cache with 32 B lines
Iter 2.1246 us
==27871== 
==27871== I   refs:      258,087,474
==27871== I1  misses:          9,987
==27871== L2i misses:          5,625
==27871== I1  miss rate:        0.00%
==27871== L2i miss rate:        0.00%
==27871== 
==27871== D   refs:       98,067,932  (73,454,588 rd + 24,613,344 wr)
==27871== D1  misses:      1,916,141  ( 1,911,775 rd +      4,366 wr)
==27871== L2d misses:        175,893  (   174,620 rd +      1,273 wr)
==27871== D1  miss rate:         1.9% (       2.6%   +        0.0%  )
==27871== L2d miss rate:         0.1% (       0.2%   +        0.0%  )
==27871== 
==27871== L2 refs:         1,926,128  ( 1,921,762 rd +      4,366 wr)
==27871== L2 misses:         181,518  (   180,245 rd +      1,273 wr)
==27871== L2 miss rate:          0.0% (       0.0%   +        0.0%  )



+ Issues:
	+ qsort 'global' closure ?
	    + Pre % the elf symbol hash data with the
	      bucket count ! :-)

	+ add an elf_link_hash_entry pointer and pass
	  that (if we can) from bfd_elf_link_record_dynamic_symbol ?
	+ then we can avoid re-calculating the symbol hash etc.
	  also get the foo to baa more nicely ... (?)
	+ fix the elf strtab leak thing ... [ugh]

** Further work
	+ sort the relocations by owner & by
	  elf_hash % owner_bucket_count


** Way better:
    + 30% faster ...
	[ for my 1 test ;-]

** For just libsvx: - each avg of 10 runs:

Unsorted:
Iter 549 ms
Iter 552 ms
Iter 550 ms
     Avg: 550ms

Sorted:
Iter 536 ms
Iter 540 ms
Iter 540 ms
     Avg: 539ms


** For libvcl: avg of 50 runs
    + with 5 of it's deps re-linked:
	+ 

Unsorted:
Iter 88.45 ms
Iter 88.27 ms
Iter 89.89 ms
Iter 88.65 ms

Sorted:
Iter 85.11 ms
Iter 85.22 ms
Iter 85.43 ms
Iter 84.57 ms

